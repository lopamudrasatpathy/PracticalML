---
title: 'Practical Machine Learning Project - Prediction of self-movement using the fitness devices'
author: "Lopamudra Satpathy"
date: "February 1, 2018"
output: html_document
---
Introduction: Using devices such as Jawbone Up, Nike Fuel Band, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These types of devices are part of the quantified self-movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of an activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumb bell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.
Here Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different classes.
1.	Class A: exactly according to the specification
2.	Class B: throwing the elbows to the front)
3.	Class C: lifting the dumbbell only halfway 
4.	Class D: lowering the dumbbell only halfway 
5.	Class E: throwing the hips to the front 
Goal: The goal of this project is to predict the way the participants exercise. Here variable "classe" is from the training dataset. The cross-validation method will be used to build the machine learning model. The expected out of sample error   should be calculated. The prediction model will predict 20 different test cases. 
Note: 
Please refer the WLE dataset for reference-
The data for this project come from this source:
 http://groupware.les.inf.puc-rio.br/har
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13). Stuttgart, Germany: ACM SIGCHI, 2013.
I want to thank the authors for their generosity to allow me to their dataset for my assignment.
Sources of dataset:
http://groupware.les.inf.puc-rio.br/har
Training set: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
Testing set: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

Data Preprocessing:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(ggplot2)
library(lattice)
library(knitr)
library(corrplot)
library(rpart)
library(rpart.plot)
library(rattle)
library(tree)
library(randomForest)
```
Loading of Dataset:
```{r}
trainurl = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl= "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainData <- read.csv(url(trainurl),header = TRUE)
testData <- read.csv(url(testurl),header = TRUE)
```
Data Cleaning:
Removing non zero variables (NA) with the mean value
```{r}
NZV <- nearZeroVar(trainData, saveMetrics = TRUE)
NZV1 <- nearZeroVar(testData, saveMetrics = TRUE)
trainData <- trainData[ ,NZV$nzv==FALSE]
testData <- testData[ ,NZV1$nzv==FALSE]

AllNA <-sapply(trainData,function(x) mean(is.na(x)))
AllNA1 <- sapply(testData, function(x)mean(is.na(x)))
trainData <- trainData[,AllNA == FALSE]
testData <-  testData[ ,AllNA1 == FALSE]

```
Removing first 5 features from the training  and testing dataset and Now number of variables are reduced to 54.
```{r}
trainData <- trainData[,-(1:5)]
testData <- testData[,-(1:5)]
dim(trainData)
dim(testData)
```
Partition of Dataset:

```{r}
inTrain <- createDataPartition(trainData$classe,p = 0.7,list=FALSE)
training <- trainData[inTrain,]
testing <- trainData[-inTrain,]
```
Correlation Analysis:
```{r}
corMatrix <- cor(training[,-54])
corrplot(corMatrix, order = "FPC", method = "color", type = "lower", tl.cex =0.8, tl.col =rgb(0,0,0))
```
Prediction Model :
1. Generalised Boosting Model(GBM)
```{r}
set.seed(12345)
controlGBM <-trainControl(method = "cv", number = 5)
ModelFitGBM <- train(classe~., data = training, method = "gbm", trControl= controlGBM, verbose = FALSE)
print(ModelFitGBM$finalModel)
```
#Prediction on Testset(GBM)
```{r}
predictionsGBM <- predict(ModelFitGBM, newdata = testing)
confusionMatrix(predictionsGBM, testing$classe)
plot(ModelFitGBM,ylim= c(0.7,1))
```
2.Random Forest Model(Using 5-fold cross validation for the algorithm)
```{r}
set.seed(12345)
controlRF <- trainControl(method = "cv", number = 5)
ModelFitRF <- train(classe~., data = training, method ="rf",trControl = controlRF, verbose = FALSE)
print(ModelFitRF$finalModel)
```
#Prediction on Testset(RF)
```{r}
predictionsRF <- predict(ModelFitRF, newdata = testing)
confusionMatrix(predictionsRF, testing$classe)
plot(ModelFitRF)
```
3. Decision Tree Model
```{r}
set.seed(12345)
ModelFitDT <- train(classe~.,data = training, method = "rpart")
print(ModelFitDT$finalModel)
```
#Prediction on Testset(DT)
```{r}
predictionDT <- predict(ModelFitDT, newdata = testing)
confusionMatrix(predictionDT, testing$classe)
fancyRpartPlot(ModelFitDT$finalModel)
```


##APPLYING THE SELECTED MODEL TO THE TEST DATA
#The accuracy for the 3 models are:
#1. GENERALL BOOSTING MODEL(GBM) : 0.9856
#2. RANDOM FOREST MODEL(RF):0.9985
#3. DECISION TREES (DT):0.53
##Best Model : Random forest Model
#The estimated accuracy of the Model
```{r}
Accuracy <- postResample(predictionsRF,testing$classe)
Accuracy
```
#The estimated out of sample error of the model
```{r}
OoSerror <- 1 - as.numeric(confusionMatrix(testing$classe, predictionsRF)$overall[1])
OoSerror
```
In this case, Random Forest model will be applied to predict 20 quiz results on testing dataset.
```{r}
predictionTest <- predict(ModelFitRF, newdata = testData)
predictionTest
```
